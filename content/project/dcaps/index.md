---
title: Behavioral Signal Processing for Diagnosing Neuropsychiatric Disorders


summary: Behavioral Signal Processing methods provide the basis for modeling human behavior with high resolution. Computational methods developed for Behavioral Signal Processing applications can provide deeper understanding of behavioral phenomena, especially useful for neuropsychiatry. I am developing methods to support dynamic analysis of clinical interviews, online data collection, and neuropsychiatric batteries. These methods are enabling understanding of mechanisms which underlie several disorders including dementia, schizophrenia, trauma, and depression. My work features analysis on the Framingham Heart Study Cognitive Aging Cohort, DCAPS Distress Corpus, and Mental Health America.

tags:
- Behavioral Signal Processing
- Vocal Biomarkers
- Neuropsychiatry
- Multimodal Machine Learning
- Natural Language Processing
- Affective Computing
- Early Diagnosis
- Prediction

date: "2022-03-06T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption:
  focal_point:

# links:
# - icon: twitter
#   icon_pack: fab
#   name: Follow
#   url: https://https://sociophysio.org/current-projects/
# url_code: ""
# url_pdf: ""
# url_slides: ""
# url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides:
---
Prior to my PhD research, I had conducted and supported a number of studies on vocal biomarkers for neuropsychiatric disorders. This included research on depression and suicidal ideation, along with dementia and cognitive decline. The research I’ve been able to publish upon has sought to measure, with more specificity, the origins of change that affect speech and language in these syndromes and disorders. Some of the findings include the capacity of 30 second free speech tasks to be used to assess suicidal ideation in online voice screening, along with the effectiveness of linguistic signals, especially driven by features derived from clinical research, in characterizing progressive cognitive decline in the Framingham Heart Study Cognitive Aging Cohort. Furthermore, I’ve also posed the potential of employing such findings as a way to augment neuropsychological testing, moving evaluation from specialist provider settings, to general practitioner clinics. 

I still continue research in this domain, with a particular interest in precise measurement of behavior. There are two ongoing projects I am still working on and seeking to publish on: the DCAPS project at USC Institute of Creative Technologies, and the PORQ study at UCSF. 

The DCAPS project involves clinical interviewing conducted by a virtual agent, also known as Ellie. This data from this project is also the same benchmarking dataset that has been used in past AVEC challenges in 2017 and 2019 at ACM Multimedia, also known as the Distress Analysis Interview Corpus (DAIC). Most recent models on analyzing behavioral indicators of neuropsychiatric disorders purport the use of a pathological/non-pathological behavioral dichotomy. However, this overlooks the behavioral heterogeneity which occurs as a result of varying dynamic behaviors in clinical interview sessions. Furthermore, it also overlooks the syndromal complexity that these “pathology” labels these models are based on. Recent clinical psychology research suggests that the application of the pathological/non-pathological dichotomy, especially via sum scores, are not sufficient for characterizing disorders such as depression. Per my work on the DCAPS project, in joint with PI’s Stefan Scherer and Mohammad Soleymani, we have developed approaches to appraise both the behavioral heterogeneity of the clinical interview sessions, and begin addressing the challenge of linking behaviors to specific symptomatology to address the syndromal complexity found in psychological disorders.

The PORQ study focuses on measuring and identifying the mechanism(s) behind human-rater identified blunted vocal affect in schizophrenia patients. Several machine learning and statistical studies on vocal aprosody (lack of intonation) in schizophrenia patients have been published, but with limited effect sizes. Thus, there is a difficulty in identifying consensus in what this perceived “blunted vocal affect” or “vocal aprosody” is coming from. In working with the UCSF BAND Lab and Dr. Ellen Bradley, we’re focusing on identifying the specific mechanism behind this change in acoustic quality of voice. By leveraging data-driven methods, we will seek to identify the mechanistic origins of blunted vocal affect in schizophrenia. With a presumed theory or model of the phenomena, we might be able to assist in longitudinal tracking of patients outside the clinic, especially with regards to medication adherence.  
